# -*- coding: utf-8 -*-
"""VA_1ND.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11bvc-oL_uCCoNovZMgHOq6QVrJyaVTna

ND1. Užduotis

Sukurti Python pagrindu veikiančią programą, kuri:

Nuskaitytų pateiktą nuotrauką ir atliktų jos vizualinę analizę.
Atpažintų ir klasifikuotų vaizdo elementus (pvz., pastatus, gamtovaizdžius, orientyrus, ženklus), kurie gali padėti nustatyti nuotraukos vietą.
Sugretintų atpažintus elementus su viešai prieinamais duomenų rinkiniais ar žinomomis vietovių nuotraukomis.
Sugeneruotų rezultatų ataskaitą su galimomis vietovėmis, pažymėtomis jų pasitikėjimo lygiais, ir vizualiai pažymėtais atpažintais objektais.
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
import torch
import clip
from PIL import Image

def load_clip_model():
    """Įkelia CLIP modelį"""
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model, preprocess = clip.load("ViT-B/32", device=device)
    return model, preprocess, device

def predict_landmark(image_path, model, preprocess, device):
    """Atpažįsta orientyrus naudojant CLIP modelį su platesniu orientyrų sąrašu"""
    image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)
    texts = [
        "Eiffel Tower in Paris", "Statue of Liberty in New York", "Big Ben in London", "Colosseum in Rome", "Taj Mahal in India",
        "Notre Dame Cathedral", "Sydney Opera House", "Mount Rushmore", "Machu Picchu in Peru", "Christ the Redeemer in Brazil",
        "Neuschwanstein Castle", "Pyramids of Giza", "Nežinoma vieta"
    ]
    text_tokens = clip.tokenize(texts).to(device)

    with torch.no_grad():
        image_features = model.encode_image(image)
        text_features = model.encode_text(text_tokens)
        similarities = (image_features @ text_features.T).softmax(dim=-1).cpu().numpy()

    best_match_idx = np.argmax(similarities)
    return texts[best_match_idx], similarities[0][best_match_idx]

def annotate_image(image_path, landmark, confidence):
    image = cv2.imread(image_path)
    label = f"{landmark} ({confidence:.2f})"
    cv2.putText(image, label, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
    return image

def display_image(image):
    plt.figure(figsize=(10, 6))
    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    plt.axis('off')
    plt.show()

def generate_report(landmark, confidence):
    print("\nGalimos nuotraukos vietos:")
    print(f"Vietovė: {landmark}, pasitikėjimo lygis: {confidence:.2f}")

def main():
    image_path = "PII_MANO_NUOTRAUKA_koliziejus.jpg"
    model, preprocess, device = load_clip_model()
    landmark, confidence = predict_landmark(image_path, model, preprocess, device)

    annotated_image = annotate_image(image_path, landmark, confidence)
    display_image(annotated_image)

    generate_report(landmark, confidence)

if __name__ == "__main__":
    main()